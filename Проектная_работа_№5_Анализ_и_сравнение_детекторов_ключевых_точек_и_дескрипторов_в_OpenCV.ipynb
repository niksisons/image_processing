{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niksisons/image_processing/blob/main/%D0%9F%D1%80%D0%BE%D0%B5%D0%BA%D1%82%D0%BD%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%965_%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B8_%D1%81%D1%80%D0%B0%D0%B2%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B4%D0%B5%D1%82%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BE%D0%B2_%D0%BA%D0%BB%D1%8E%D1%87%D0%B5%D0%B2%D1%8B%D1%85_%D1%82%D0%BE%D1%87%D0%B5%D0%BA_%D0%B8_%D0%B4%D0%B5%D1%81%D0%BA%D1%80%D0%B8%D0%BF%D1%82%D0%BE%D1%80%D0%BE%D0%B2_%D0%B2_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Проектная работа №5. Анализ и сравнение детекторов ключевых точек и дескрипторов в OpenCV**"
      ],
      "metadata": {
        "id": "5mVzcfdoNabV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **1. Цель работы**\n",
        "\n"
      ],
      "metadata": {
        "id": "7nPgXQS6NdDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнить экспериментальное исследование детекторов и дескрипторов ключевых точек (Harris, FAST, ORB, SIFT, AKAZE, BRISK и др.) в различных условиях и для разных типов изображений, оценить их качество и производительность по заданным метрикам и сформулировать рекомендации по выбору оптимальных комбинаций «детектор + дескриптор» для конкретных задач."
      ],
      "metadata": {
        "id": "9qwsO-QpNduF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Задачи работы**\n"
      ],
      "metadata": {
        "id": "TcA2kLalNg3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Сравнить** работу детекторов и дескрипторов в экстремальных условиях (размытие, шум, сжатие и др.) и оценить их устойчивость, точность локализации и скорость (Задание 1).\n",
        "2. **Исследовать** мультимодальное сопоставление изображений (RGB/IR, день/ночь, спутник/карта и др.) и оценить качество сопоставлений по метрикам Precision/Recall, F1, ROC-AUC (Задание 2).\n",
        "3. **Оценить** поведение детекторов/дескрипторов в специфических доменах (медицина, текстуры, документы) по профильным метрикам (регистрация, различимость текстур, качество OCR) (Задание 3).\n",
        "5. **Собрать и проанализировать** результаты в виде таблиц, графиков и визуализаций, **сделать выводы** и **дать рекомендации** по выбору методов."
      ],
      "metadata": {
        "id": "nu2BuN7HNgN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "ppmJoMdhNodl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## **3. Подготовка рабочей среды и данных**"
      ],
      "metadata": {
        "id": "wN1CXS99NnsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **3.1. Настройка окружения**\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "- Установить/проверить наличие библиотек:\n",
        "  - `opencv-python` (cv2)\n",
        "  - `numpy`\n",
        "  - `matplotlib`\n",
        "  - при необходимости для метрик классификации — `scikit-learn` (можно обойтись и без него, но он упрощает построение PR/ROC).\n",
        "- Настроить рабочую среду (Jupyter Notebook / Google Colab / локальный Python-скрипт).\n",
        "- Собрать набор тестовых изображений (из интернета):\n",
        "  - натурные сцены с текстурами (здания, природные объекты, городские сцены),\n",
        "  - сцены с текстом (документы, вывески),\n",
        "  - текстурные поверхности (ткани, дерево, бетон),\n",
        "  - пары для мультимодальных задач (день/ночь, спутник/карта, RGB/IR — при наличии),\n",
        "  - при желании — медицинские изображения (рентген, МРТ и т.п.).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SMYAmtaoNmtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# Базовые импорты"
      ],
      "metadata": {
        "id": "gwR8UjBkOxtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "57T-6m5UNslH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### **3.2. Базовые функции для работы с изображениями**\n",
        "\n",
        "**Что нужно реализовать:**\n",
        "\n",
        "1. **Функции загрузки** изображений с диска по пути (с возможным приведением к одному размеру при необходимости).\n",
        "2. **Функцию визуализации** одного или нескольких изображений в виде сетки (matplotlib).\n",
        "3. (Опционально) Функцию перевода в оттенки серого и нормализации.\n"
      ],
      "metadata": {
        "id": "fNTsbaxyNrgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# Функции:\n",
        "# - load_image(path)\n",
        "# - show_images(list_of_images, titles=None, cols=...)"
      ],
      "metadata": {
        "id": "1EEJvG_cOtmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **3.3. Базовые функции измерения времени**\n",
        "\n",
        "**Что нужно реализовать:**\n",
        "\n",
        "- Простую функцию-обёртку для замера времени выполнения произвольной операции (например, детекция и описание ключевых точек).\n",
        "\n",
        "**Пояснение:**  \n",
        "Эта функция будет использоваться в Задании 1 для измерения производительности (время на одно изображение и FPS).\n",
        "\n"
      ],
      "metadata": {
        "id": "DAxqYER4Nw2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "\n",
        "# Функция:\n",
        "# - measure_time(func, *args, **kwargs) -> (result, elapsed_time)"
      ],
      "metadata": {
        "id": "WGMxE4ICO-o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Задание 1. Сравнительный анализ детекторов в экстремальных условиях**\n",
        "\n"
      ],
      "metadata": {
        "id": "AOofLdsHN4fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1. Формирование датасета с искажениями**"
      ],
      "metadata": {
        "id": "qsDQ41M8N5I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "**Цель:**  \n",
        "Проверить устойчивость детекторов/дескрипторов к различным искажениям изображения.\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Выбрать **несколько базовых изображений** (3–5 штук) с богатыми текстурами и структурой:\n",
        "   - городские сцены (здания),\n",
        "   - природные сцены (лес, горы),\n",
        "   - технические объекты (машины, здания с повторяющимися элементами).\n",
        "\n",
        "2. Для каждого базового изображения сгенерировать **варианты с искажениями**:\n",
        "   - **Размытие движения (motion blur)** — свёртка с линейным фильтром.\n",
        "   - **Изменение освещения**:\n",
        "     - затемнение / осветление (умножение на коэффициент, добавление смещения),\n",
        "     - имитация «день/ночь» (снижение яркости, усиление контраста).\n",
        "   - **Поворот и масштабирование** (cv2.warpAffine / cv2.resize).\n",
        "   - **Шум**:\n",
        "     - гауссовский (добавление случайной компоненты),\n",
        "     - импульсный («соль и перец»).\n",
        "   - **Сжатие JPEG** с разным качеством (cv2.imwrite с параметром `cv2.IMWRITE_JPEG_QUALITY`).\n",
        "\n",
        "3. Для части искажений, где это возможно (поворот, масштаб, аффинное/проективное преобразование), **сохранять или вычислять известное преобразование** (матрицу аффинного преобразования или гомографии), чтобы использовать её для расчёта метрик (повторяемость, точность локализации)."
      ],
      "metadata": {
        "id": "GsrpaRK_N7fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "\n",
        "# Функции для аугментации:\n",
        "#\n",
        "# - apply_motion_blur(image, kernel_size, direction=...)\n",
        "# - change_brightness_contrast(image, alpha, beta)\n",
        "# - add_gaussian_noise(image, sigma)\n",
        "# - add_salt_pepper_noise(image, amount)\n",
        "# - jpeg_compress_decompress(image, quality)\n"
      ],
      "metadata": {
        "id": "xMIWabcuOiwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "JiJ0o7jpOEt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **4.2. Реализация пайплайна «детектор + дескриптор + сопоставление»**"
      ],
      "metadata": {
        "id": "uQb0ADDSOD5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Выбрать набор комбинаций:\n",
        "   - SIFT (детектор+дескриптор),\n",
        "   - ORB (детектор+дескриптор),\n",
        "   - AKAZE (детектор+дескриптор),\n",
        "   - FAST + SIFT (быстрый детектор, «тяжёлый» дескриптор),\n",
        "   - BRISK (детектор+дескриптор) — при желании.\n",
        "\n",
        "2. Для каждой комбинации реализовать:\n",
        "   - детекцию ключевых точек на **оригинальном** и **искажённом** изображениях;\n",
        "   - вычисление дескрипторов;\n",
        "   - сопоставление (например, BFMatcher c расстоянием Хэмминга для бинарных дескрипторов и L2 для вещественных).\n",
        "\n"
      ],
      "metadata": {
        "id": "rBZz1gaQOCee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код (См. теорию)\n",
        "# - detect_and_describe(image, method=\"SIFT\"/\"ORB\"/\"AKAZE\"/\"FAST+SIFT\")\n",
        "# - match_descriptors(desc1, desc2, method=\"BF\"/\"FLANN\")"
      ],
      "metadata": {
        "id": "szatmmWpObMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "rV68529sOJuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### **4.3. Метрики для оценки**"
      ],
      "metadata": {
        "id": "YzMrDhMvOJBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.3.1. Повторяемость (repeatability)**"
      ],
      "metadata": {
        "id": "Lp3x9eE4OWRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Смысл метрики:**  \n",
        "Показывает, какой процент ключевых точек, найденных на одном изображении, можно «узнать» на другом при известном геометрическом преобразовании (аффинном или гомографии).\n",
        "\n",
        "**Идея:**\n",
        "\n",
        "1. Имеем:\n",
        "   - набор ключевых точек `kp1` на изображении 1,\n",
        "   - набор ключевых точек `kp2` на изображении 2,\n",
        "   - известную матрицу преобразования `H` (гомография или аффинное преобразование).\n",
        "2. Преобразуем координаты `kp1` в систему координат второго изображения.\n",
        "3. Считаем, что точка повторилась, если в окрестности радиуса `r` от преобразованной точки есть ключевая точка из `kp2`.\n",
        "4. Повторяемость =  \n",
        "   $\n",
        "   \\text{repeatability} = \\frac{N_{\\text{совпавших}}}{\\min(N_1, N_2)}\n",
        "   \\times 100\\%\n",
        "   $"
      ],
      "metadata": {
        "id": "t_FeBcoZVeT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def keypoints_to_array(keypoints):\n",
        "    \"\"\"\n",
        "    Преобразует список cv2.KeyPoint в массив координат shape (N, 2).\n",
        "    \"\"\"\n",
        "    return np.array([kp.pt for kp in keypoints], dtype=np.float32)\n",
        "\n",
        "def transform_points(points, H):\n",
        "    \"\"\"\n",
        "    Преобразует точки (x, y) матрицей гомографии H.\n",
        "    \n",
        "    points: np.array shape (N, 2)\n",
        "    H: np.array shape (3, 3)\n",
        "    \"\"\"\n",
        "    num = points.shape[0]\n",
        "    # Добавляем однородную координату\n",
        "    pts_h = np.hstack([points, np.ones((num, 1), dtype=np.float32)])\n",
        "    pts_t = (H @ pts_h.T).T   # shape (N, 3)\n",
        "    # Переход обратно к декартовым координатам\n",
        "    pts_t = pts_t[:, :2] / pts_t[:, 2:3]\n",
        "    return pts_t\n",
        "\n",
        "def compute_repeatability(kp1, kp2, H_1_to_2, radius=3.0, image_shape_2=None):\n",
        "    \"\"\"\n",
        "    Вычисляет повторяемость ключевых точек.\n",
        "    \n",
        "    kp1, kp2: списки cv2.KeyPoint для изображений 1 и 2.\n",
        "    H_1_to_2: матрица гомографии (из 1 в 2).\n",
        "    radius: допустимое отклонение (в пикселях) для совпадения точки.\n",
        "    image_shape_2: (h, w) изображения 2 для ограничения области (опционально).\n",
        "    \"\"\"\n",
        "    if len(kp1) == 0 or len(kp2) == 0:\n",
        "        return 0.0, 0\n",
        "    \n",
        "    pts1 = keypoints_to_array(kp1)  # (N1, 2)\n",
        "    pts2 = keypoints_to_array(kp2)  # (N2, 2)\n",
        "    \n",
        "    # Преобразуем точки из изображения 1 в систему координат 2-го\n",
        "    pts1_t = transform_points(pts1, H_1_to_2)  # (N1, 2)\n",
        "    \n",
        "    # Опционально отбрасываем точки, которые вышли за границы 2-го изображения\n",
        "    if image_shape_2 is not None:\n",
        "        h2, w2 = image_shape_2[:2]\n",
        "        mask_inside = (\n",
        "            (pts1_t[:, 0] >= 0) & (pts1_t[:, 0] < w2) &\n",
        "            (pts1_t[:, 1] >= 0) & (pts1_t[:, 1] < h2)\n",
        "        )\n",
        "        pts1_t = pts1_t[mask_inside]\n",
        "    \n",
        "    if pts1_t.shape[0] == 0:\n",
        "        return 0.0, 0\n",
        "    \n",
        "    # Для поиска ближайших точек можно использовать простой перебор\n",
        "    # (для учебных размеров этого достаточно).\n",
        "    matched = 0\n",
        "    for p in pts1_t:\n",
        "        dists = np.linalg.norm(pts2 - p[None, :], axis=1)\n",
        "        if np.min(dists) <= radius:\n",
        "            matched += 1\n",
        "    \n",
        "    N1 = pts1_t.shape[0]\n",
        "    N2 = pts2.shape[0]\n",
        "    denominator = max(1, min(N1, N2))\n",
        "    \n",
        "    repeatability = matched / denominator * 100.0\n",
        "    return repeatability, matched\n",
        "```"
      ],
      "metadata": {
        "id": "N02xfo0VOHrb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "#### **4.3.2. Точность локализации (mean localization error)**"
      ],
      "metadata": {
        "id": "PIpFjBkeVl5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Смысл метрики:**  \n",
        "Если у нас есть пары «соответствующих» точек, можно измерить среднее расстояние между реальным положением точки и предсказанным (по гомографии). Чем меньше ошибка, тем лучше локализация.\n",
        "\n",
        "**Идея (упрощённо):**\n",
        "\n",
        "- Для каждой пары соответствий `(p1, p2)`:\n",
        "  - преобразуем `p1` матрицей `H` → `p1’`,\n",
        "  - считаем расстояние `d = ||p1’ − p2||`,\n",
        "- Средняя ошибка — среднее значение `d` по всем «хорошим» соответствиям (например, инлайерам RANSAC)."
      ],
      "metadata": {
        "id": "SgXShR7HVhoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "```python\n",
        "def compute_localization_error(matches, kp1, kp2, H_1_to_2, inlier_mask=None):\n",
        "    \"\"\"\n",
        "    Вычисляет среднюю ошибку локализации по сопоставлениям.\n",
        "    \n",
        "    matches: список cv2.DMatch (обычно после фильтрации и RANSAC).\n",
        "    kp1, kp2: списки cv2.KeyPoint для изображений 1 и 2.\n",
        "    H_1_to_2: матрица гомографии.\n",
        "    inlier_mask: опциональная маска инлайеров (список или np.array из 0/1).\n",
        "    \"\"\"\n",
        "    if len(matches) == 0:\n",
        "        return None\n",
        "    \n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "    for i, m in enumerate(matches):\n",
        "        if (inlier_mask is not None) and (not inlier_mask[i]):\n",
        "            continue\n",
        "        pts1.append(kp1[m.queryIdx].pt)\n",
        "        pts2.append(kp2[m.trainIdx].pt)\n",
        "    \n",
        "    if len(pts1) == 0:\n",
        "        return None\n",
        "    \n",
        "    pts1 = np.array(pts1, dtype=np.float32)\n",
        "    pts2 = np.array(pts2, dtype=np.float32)\n",
        "    \n",
        "    pts1_t = transform_points(pts1, H_1_to_2)\n",
        "    errors = np.linalg.norm(pts1_t - pts2, axis=1)\n",
        "    return float(np.mean(errors)), errors\n",
        "```\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ugj0YTHIPKvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.3.3. Время выполнения и FPS**\n",
        "\n",
        "**Смысл:**  \n",
        "Оценить, сколько времени занимает полный пайплайн (детекция + дескрипторы + сопоставление) на одном изображении и как это зависит от разрешения.\n",
        "\n",
        "**Идея:**\n",
        "\n",
        "- Для каждой комбинации (метод, разрешение) измеряем среднее время по нескольким запускам.\n",
        "- FPS ≈ 1 / (среднее время кадра).\n",
        "\n",
        "```python\n",
        "import time\n",
        "\n",
        "def measure_pipeline_time(pipeline_func, image1, image2, runs=5):\n",
        "    \"\"\"\n",
        "    Измеряет среднее время выполнения пользовательского пайплайна.\n",
        "    \n",
        "    pipeline_func: функция, внутри которой выполняются\n",
        "                   детекция, вычисление дескрипторов и сопоставление.\n",
        "    image1, image2: пара изображений.\n",
        "    \"\"\"\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        start = time.time()\n",
        "        _ = pipeline_func(image1, image2)\n",
        "        times.append(time.time() - start)\n",
        "    mean_time = np.mean(times)\n",
        "    fps = 1.0 / mean_time if mean_time > 0 else None\n",
        "    return mean_time, fps, times\n",
        "```\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FBMLOFhePNFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4.3.4. Процент правильных сопоставлений и устойчивость к выбросам (RANSAC inliers)**\n"
      ],
      "metadata": {
        "id": "yaznBHk1VqiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**Смысл:**\n",
        "\n",
        "- **Процент правильных сопоставлений** — доля инлайеров (правильных соответствий) среди всех найденных сопоставлений.\n",
        "- **Устойчивость к выбросам** — насколько хорошо метод справляется с ложными сопоставлениями (высокий процент инлайеров = хорошая устойчивость).\n",
        "\n",
        "**Типичный сценарий:**\n",
        "\n",
        "1. Получили список сопоставлений `matches`.\n",
        "2. Построили гомографию через `cv2.findHomography(..., method=cv2.RANSAC, ...)`, получили маску инлайеров `mask`.\n",
        "3. Считаем процент инлайеров.\n",
        "\n",
        "```python\n",
        "def compute_inlier_ratio(matches_mask):\n",
        "    \"\"\"\n",
        "    Вычисляет долю инлайеров по маске, возвращаемой cv2.findHomography.\n",
        "    \n",
        "    matches_mask: np.array или список 0/1 (или True/False),\n",
        "                  длина равна числу сопоставлений, поданных в findHomography.\n",
        "    \"\"\"\n",
        "    mask = np.array(matches_mask).astype(bool)\n",
        "    total = len(mask)\n",
        "    if total == 0:\n",
        "        return 0.0, 0\n",
        "    inliers = np.sum(mask)\n",
        "    ratio = inliers / total * 100.0\n",
        "    return ratio, inliers\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "62yl2nVOPI_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.4. Проведение экспериментов и сбор результатов**\n"
      ],
      "metadata": {
        "id": "i3r6dZFOPOv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Для каждой комбинации детектор+дескриптор (SIFT, ORB, AKAZE, FAST+SIFT, BRISK и т.п.) и каждого типа искажения:\n",
        "   - измерить **повторяемость**;\n",
        "   - измерить **точность локализации** (при наличии гомографии);\n",
        "   - измерить **время выполнения** и **FPS**;\n",
        "   - вычислить **процент инлайеров (inlier ratio)** после RANSAC.\n",
        "\n",
        "2. Свести результаты в таблицы, например:\n",
        "\n",
        "| Метод | Искажение | Repeatability (%) | Loc. error (px) | Inliers (%) | Time (s) | FPS |\n",
        "|-------|-----------|-------------------|------------------|-------------|----------|-----|\n",
        "\n",
        "3. Построить графики:\n",
        "   - зависимость времени/кол-ва ключевых точек от разрешения;\n",
        "   - зависимость метрик от силы искажения (например, длина размытия, уровень шума, степень сжатия)."
      ],
      "metadata": {
        "id": "aGioOik-PQRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - Цикл по методам и искажениям\n",
        "# - Вычисление метрик через описанные выше функции\n",
        "# - Формирование таблиц (pandas или простые списки)\n",
        "# - Построение графиков (matplotlib)"
      ],
      "metadata": {
        "id": "Nu2KPVz6PVaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Задание 2. Мультимодальное сопоставление изображений**\n"
      ],
      "metadata": {
        "id": "zuduMQttPeci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.1. Подбор мультимодальных пар**\n"
      ],
      "metadata": {
        "id": "Te_I_5ggVsyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Варианты пар (минимум 2–3 типа):**\n",
        "\n",
        "1. **RGB vs инфракрасные** (если найдёте открытые пары в интернете).\n",
        "2. **День vs ночь** (одна и та же сцена).\n",
        "3. **Спутниковые снимки vs карты** (Google Maps / OpenStreetMap / топографические карты).\n",
        "4. **Исторические фото vs современные** (одна и та же улица, здание).\n",
        "\n",
        "**Требование:**  \n",
        "Для каждой пары кратко описать:\n",
        "- источник изображений,\n",
        "- основные отличия (контраст, шум, ракурс, сезон, освещение).\n"
      ],
      "metadata": {
        "id": "DidMFmOqPY8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# Загрузка и визуализация выбранных пар изображений"
      ],
      "metadata": {
        "id": "VjXIYlUbPaLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "- При необходимости привести изображения к одному размеру.\n",
        "- Применить предобработку:\n",
        "  - перевод в оттенки серого,\n",
        "  - выравнивание гистограммы (`cv2.equalizeHist`),\n",
        "  - CLAHE (адаптивное выравнивание `cv2.createCLAHE`) — особенно полезно для слабоконтрастных изображений.\n",
        "- Сравнить, влияет ли предобработка на качество сопоставления.\n",
        "\n"
      ],
      "metadata": {
        "id": "x17xxd1BPgKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# Функции:\n",
        "# - preprocess_gray(image, use_clahe=False)\n",
        "# - сравнение работы \"до\" и \"после\" предобработки"
      ],
      "metadata": {
        "id": "GAb0ktMiY4fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3. Сравнение SIFT vs ORB vs AKAZE для кросс-модальных задач**\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Для каждой мультимодальной пары:\n",
        "   - запустить пайплайн с SIFT,\n",
        "   - отдельно с ORB,\n",
        "   - отдельно с AKAZE.\n",
        "2. Выполнить сопоставление дескрипторов (BFMatcher или FLANN).\n",
        "3. При необходимости применить тест Лоу для отбраковки ложных срабатываний (особенно для SIFT/AKAZE).\n",
        "\n"
      ],
      "metadata": {
        "id": "_MilgXj9Y8SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код"
      ],
      "metadata": {
        "id": "-BIqrfhoY-7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **5.4. Метрики: Precision/Recall, F1-score, ROC-AUC**"
      ],
      "metadata": {
        "id": "XyAWQYkNZK-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "**Смысл:**\n",
        "\n",
        "- Рассматриваем каждое сопоставление как бинарное решение:\n",
        "  - **1 (true)** — правильное соответствие (инлайер),\n",
        "  - **0 (false)** — неправильное соответствие (аутлайер).\n",
        "- Имеем:\n",
        "  - истинные метки (из маски RANSAC или из заранее подготовленной разметки),\n",
        "  - некоторую «оценку качества» (например, расстояние между дескрипторами).\n",
        "\n",
        "**Определения:**\n",
        "\n",
        "- **Precision (точность)**:  \n",
        "  $\n",
        "  \\text{Precision} = \\frac{TP}{TP + FP}\n",
        "  $\n",
        "- **Recall (полнота)**:  \n",
        "  $\n",
        "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
        "  $\n",
        "- **F1-score**:  \n",
        "  $\n",
        "  F1 = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "  $\n",
        "- **ROC-AUC** — площадь под ROC-кривой (TPR vs FPR при разных порогах).\n",
        "\n"
      ],
      "metadata": {
        "id": "v8tQgbYBZOTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "def compute_pr_f1_from_matches(distances, inlier_mask, threshold):\n",
        "    \"\"\"\n",
        "    Вычисляет Precision, Recall и F1 для заданного порога расстояния.\n",
        "    \n",
        "    distances: np.array shape (N,) - расстояния между дескрипторами\n",
        "               (например, m.distance из cv2.DMatch).\n",
        "    inlier_mask: np.array shape (N,) - 1 для инлайеров, 0 для аутлайеров\n",
        "                 (по результату RANSAC или разметки).\n",
        "    threshold: порог по расстоянию, ниже которого считаем предсказание \"пара является совпадением\".\n",
        "    \"\"\"\n",
        "    distances = np.array(distances, dtype=np.float32)\n",
        "    y_true = np.array(inlier_mask).astype(int)  # 1 - правильное совпадение, 0 - ложное\n",
        "    \n",
        "    # Предсказание: 1 если расстояние <= threshold, иначе 0\n",
        "    y_pred = (distances <= threshold).astype(int)\n",
        "    \n",
        "    TP = np.sum((y_pred == 1) & (y_true == 1))\n",
        "    FP = np.sum((y_pred == 1) & (y_true == 0))\n",
        "    FN = np.sum((y_pred == 0) & (y_true == 1))\n",
        "    \n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "    \n",
        "    return precision, recall, f1, TP, FP, FN\n",
        "```\n"
      ],
      "metadata": {
        "id": "AcQ-stiNY99S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - получение distances и inlier_mask из сопоставлений\n",
        "# - вычисление PR/F1 для нескольких порогов\n",
        "# - построение графиков Precision–Recall и зависимости F1 от порога"
      ],
      "metadata": {
        "id": "2Rq-jFzLZbJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.5. Средняя ошибка репроекции**\n"
      ],
      "metadata": {
        "id": "AK7BSDfQZn-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Смысл:**  \n",
        "Похож на «точность локализации» из Задания 1, но теперь нас интересует, насколько хорошо гомография «переносятся» соответствующие точки с одного изображения на другое.\n",
        "\n",
        "Можно использовать уже реализованную ранее функцию `compute_localization_error`, рассматривая среднюю ошибку как **среднюю ошибку репроекции**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1H2UJp5NZfWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - вычисление гомографии для мультимодальных пар\n",
        "# - использование compute_localization_error для оценки"
      ],
      "metadata": {
        "id": "uL1X7bB0Zjzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **5.6. Анализ: влияние предобработки и выбор метода**"
      ],
      "metadata": {
        "id": "zaSbwMSQZrQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "- Сравнить:\n",
        "  - SIFT / ORB / AKAZE по метрикам PR, F1, ROC-AUC (при необходимости),\n",
        "  - результаты до и после CLAHE / эквализации гистограммы.\n",
        "- Сделать выводы:\n",
        "  - какие методы лучше для кросс-модальных пар,\n",
        "  - помогает ли предобработка и для каких типов изображений."
      ],
      "metadata": {
        "id": "_9X2rXWcZsvg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "```python\n",
        "# Ваш код\n",
        "# - формирование таблиц и графиков для мультимодальных экспериментов\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yNlW3QLDZqTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **6. Задание 3. Детекторы для специфических доменов**\n",
        "\n"
      ],
      "metadata": {
        "id": "Wb32eMm1ZvVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ВЫБРАТЬ ОДИН ПУНКТ ПО ЖЕЛАНИЮ**"
      ],
      "metadata": {
        "id": "lPIDl1s7bldf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1. Медицинские изображения**"
      ],
      "metadata": {
        "id": "L_9FxBz_Zv3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Подобрать несколько медицинских изображений (рентген, МРТ, УЗИ) одного и того же анатомического региона, но снятых:\n",
        "   - в разное время,\n",
        "   - с немного разным масштабом/углом,\n",
        "   - либо с небольшими сдвигами.\n",
        "\n",
        "2. Реализовать регистрацию (выравнивание) пары изображений с помощью ключевых точек:\n",
        "   - детекция и дескрипторы (например, SIFT / ORB / AKAZE),\n",
        "   - сопоставление,\n",
        "   - оценка гомографии или аффинного преобразования,\n",
        "   - выравнивание одного изображения под другое.\n",
        "\n",
        "3. **Метрика:** точность регистрации изображений:\n",
        "   - можно измерять среднюю ошибку репроекции на опорных точках (анатомические ориентиры),\n",
        "   - либо визуально оценивать перекрытие (разница изображений до и после выравнивания)."
      ],
      "metadata": {
        "id": "UA4o3TQwZxXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - сопоставление пар медицинских изображений через ключевые точки\n",
        "# - использование compute_localization_error для оценки"
      ],
      "metadata": {
        "id": "vJSHR1qCZyqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **6.2. Текстуры и паттерны**"
      ],
      "metadata": {
        "id": "cZ_T_awfZ5au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Подобрать наборы текстур:\n",
        "   - ткани (разные узоры),\n",
        "   - природные текстуры (камень, дерево, трава),\n",
        "   - техногенные (плитка, кирпич, асфальт и др.).\n",
        "\n",
        "2. Задача: **оценить различимость похожих текстур**:\n",
        "   - для каждой пары текстур (одинаковые/разные) вычислить ключевые точки и дескрипторы;\n",
        "   - сопоставить дескрипторы между:\n",
        "     - одинаковыми текстурами (разные кадры),\n",
        "     - разными текстурами (по смыслу «не совпадают»).\n",
        "\n",
        "3. Простая метрика различимости:\n",
        "   - количество «хороших» совпадений (инлайеров) между:\n",
        "     - `same_textures` — должно быть **высоким**,\n",
        "     - `different_textures` — должно быть **низким**;\n",
        "   - можно использовать отношение:\n",
        "$$\n",
        "R = \\frac{\\text{инлайеры между одинаковыми текстурами}}{\\text{инлайеры между разными текстурами}}\n",
        "$$\n",
        "\n",
        "     Чем выше `R`, тем лучше алгоритм различает текстуры."
      ],
      "metadata": {
        "id": "wulNq5cBZ4S8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - эксперименты с текстурами\n",
        "# - подсчёт количества инлайеров для \"похожих\" и \"непохожих\" пар"
      ],
      "metadata": {
        "id": "KTLdO3B9Z8aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. Документы и текст (перспективные искажения и OCR)**\n"
      ],
      "metadata": {
        "id": "Y3OCuCp4aSiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Что нужно сделать:**\n",
        "\n",
        "1. Подобрать изображения документов:\n",
        "   - прямой скан/фото (почти без искажений),\n",
        "   - тот же документ, снятый под углом (перспектива), с небольшими искажениями.\n",
        "\n",
        "2. Задача:\n",
        "   - по ключевым точкам оценить гомографию и выровнять перспективу документа (получить «квазискан»);\n",
        "   - применить к выровненному изображению OCR (например, Tesseract, если есть возможность, либо любой другой распознаватель текста) — **не обязательно в коде, можно вручную/сторонним ПО**.\n",
        "\n",
        "3. **Метрика:** качество OCR после выравнивания:\n",
        "   - простой вариант: взять несколько строк текста и вручную посчитать **долю правильно распознанных символов**,\n",
        "   - формула точности по символам:\n",
        "$\n",
        "\\text{Accuracy} = 1 - \\frac{\\text{редакционное расстояние (Levenshtein)}}{\\text{длина эталонного текста}}\n",
        "$\n",
        "\n",
        "Пример небольшой функции для подсчёта точности по строкам (при условии, что вы уже получили `gt_text` (эталонный текст) и `pred_text` (текст полученный OCR после выравнивания):\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "unD0PuUbaAYL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```python\n",
        "def char_accuracy(gt_text, pred_text):\n",
        "    \"\"\"\n",
        "    Простейшая оценка точности по символам:\n",
        "    Accuracy = 1 - (редакционное расстояние / длина эталонного текста).\n",
        "    Для учебных целей можно реализовать грубое расстояние Левенштейна\n",
        "    или просто посчитать долю совпадающих символов на пересечении длин.\n",
        "    \"\"\"\n",
        "    gt = str(gt_text)\n",
        "    pr = str(pred_text)\n",
        "    \n",
        "    n = min(len(gt), len(pr))\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    matches = sum(1 for i in range(n) if gt[i] == pr[i])\n",
        "    return matches / len(gt) * 100.0\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Bxnu0DDpWrOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(Для серьёзной оценки лучше использовать полноценный алгоритм Левенштейна, но в рамках работы достаточно даже грубого приближения.)*"
      ],
      "metadata": {
        "id": "BKu6zLU5WsR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код\n",
        "# - выравнивание документа по гомографии\n",
        "# - передача результата в систему OCR (опционально)\n",
        "# - расчёт простой метрики точности распознавания"
      ],
      "metadata": {
        "id": "1a85kVMuaOX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **7. Результаты**"
      ],
      "metadata": {
        "id": "qJgmbIjkbRDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Каждая работа должна содержать:\n",
        "\n",
        "1. **Результаты**\n",
        "   - Таблицы сравнения метрик для разных методов и условий:\n",
        "     - для Задания 1 — по искажениям,\n",
        "     - для Задания 2 — по мультимодальным парам,\n",
        "     - для Задания 3 — по доменам,\n",
        "   - Графики:\n",
        "     - зависимость времени и количества ключевых точек от разрешения,\n",
        "     - зависимость метрик от силы искажений (blur, noise, JPEG),\n",
        "     - Precision–Recall / F1 от порога (для мультимодальных задач),\n",
        "   - Визуализации:\n",
        "     - ключевые точки на изображениях,\n",
        "     - сопоставления (линии между изображениями),\n",
        "     - карты инлайеров/аутлайеров,\n",
        "     - результаты выравнивания (до/после гомографии, до/после коррекции перспективы)."
      ],
      "metadata": {
        "id": "e27SKp8NbZuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код (ЕСЛИ ВСЕ ЭТО ОТСУТСТВУЕТ В ОТВЕТЕ НА КАЖДОЕ ЗАДАНИЕ)\n",
        "# - формирование и вывод таблиц (pandas DataFrame или списки)\n",
        "# - построение всех необходимых графиков\n",
        "# - сохранение ключевых изображений с визуализацией"
      ],
      "metadata": {
        "id": "AcOK6PHebbPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **8. Анализ**\n",
        "\n",
        "В разделе анализа рекомендуется:\n",
        "\n",
        "1. Проверить **статистическую значимость различий**, где это оправдано:\n",
        "   - сравнение средних значений метрик для разных методов (при многократных запусках).\n",
        "2. Выполнить **корреляционный анализ метрик**:\n",
        "   - как связаны время работы и качество (повторяемость, inlier ratio и т.п.);\n",
        "   - как связаны разные метрики между собой (например, repeatability и процент инлайеров).\n",
        "3. Выявить **закономерности**:\n",
        "   - какие методы устойчивее к размытиям, шумам, сжатию,\n",
        "   - какие комбинации лучше для кросс-модальных пар,\n",
        "   - какие методы хорошо ведут себя на медицинских/текстурных/документальных изображениях,\n"
      ],
      "metadata": {
        "id": "Ix3CcixM0hwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ВАШ ОТВЕТ**"
      ],
      "metadata": {
        "id": "dTZ31Y1JXL3_"
      }
    }
  ]
}