# Спецификация требований (SRS) для системы автоматизации деплоя микросервисов

## 1. ВВЕДЕНИЕ

### 1.1 Цель документа

Этот документ описывает требования к информационной системе, предназначенной для автоматизации процессов сборки, тестирования, публикации образов, развертывания микросервисов и мониторинга их состояния. Цель — зафиксировать функциональные и нефункциональные требования, интерфейсы, ограничения и условия приёмки, чтобы разработчики, DevOps-инженеры и тестировщики имели единое понимание, что должно быть реализовано.

### 1.2 Область применения

Система предназначена для локальной (on-prem) инфраструктуры, с собственным экземпляром CI/CD (self-managed), registry, Kubernetes-кластерами (dev и prod), Helm-деплоем, объектным хранилищем, системой мониторинга и логирования. Система будет использоваться для автоматизации жизненного цикла микросервисов (от кода до деплоя и мониторинга), включая сборку, тестирование, пуш образов, деплой, откат(rollback), мониторинг, alerting, логирование.

Система **не** охватывает: управление базами данных сервисов на уровне схем, реализацию бизнес-логики самих микросервисов, UI/UX фронтенда (кроме что касается деплоем и конфигурации), управление инфраструктурой вне Kubernetes (например, bare-metal provisioning).

### 1.3 Определения, сокращения

* SRS — Software Requirements Specification
* CI/CD — Continuous Integration / Continuous Deployment
* Registry — Docker/OCI registry (например, GitLab Registry, Harbor)
* Helm — система управления пакетом Kubernetes-чартов
* Cluster — Kubernetes cluster (dev или prod)
* Artifact — артефакт сборки (docker image, бинарь, артефакт тестов)
* Release — выпуск приложения, развернутый в кластере через Helm
* Monitoring — система мониторинга (Prometheus + Grafana)
* Alert — система оповещений на основе метрик/состояния сервисов
* DevOps — пользователь с правами администрирования CI/CD и кластера

### 1.4 Ссылки

* ISO/IEC/IEEE 29148 — стандарт по спецификации требований к ПО.
* IEEE 830-1998 — рекомендуемая структура SRS.
* Документация по использованию GitLab CI/CD, Helm, Kubernetes, Prometheus.

---

## 2. ОБЩЕЕ ОПИСАНИЕ

### 2.1 Контекст системы

Система выполняется в инфраструктуре заказчика, на выделенных серверах / bare-metal / виртуальных машинах. Система включает в себя следующие компоненты: self-managed GitLab (репозиторий + CI/CD), реестр образов (registry), Kubernetes-кластеры (dev и prod), Helm-чарты, объектное хранилище, мониторинг/логирование.

Система взаимодействует с внешними элементами: DNS/Ingress (для доступа к сервисам), системой уведомлений (alerting — e-mail/Slack), системой хранения (Ceph/Rook), возможно — внешними API, базами данных, брокерами сообщений (RabbitMQ), внешними сервисами.

### 2.2 Функции системы — на высоком уровне

* Управление репозиториями кода и триггерами CI/CD при коммите или MR
* Сборка, тестирование, упаковка образов
* Публикация образов в registry
* Автоматическое (и ручное) развертывание (dev / prod) через Helm / Kubernetes
* Возможность rollback’а на предыдущие стабильные версии
* Управление конфигурациями (значения чарта, переменные окружения, домены)
* Мониторинг состояния сервисов, сбор метрик, логирование, alerting
* Управление доступом и ролями (DevOps, разработчики, администраторы)
* Хранение артефактов и метаданных (artifacts, images, releases, logs)

### 2.3 Характеристики пользователей

* **Разработчики** — пишут код, делают коммиты/MR, ожидают автоматического билда и deploy в dev, просмотр статусa CI.
* **DevOps / Администраторы** — управляют CI/CD, runner’ами, кластерами, мониторингом, доступны средства отката, управления конфигурацией, безопасности.
* **Администраторы/Операторы** — отвечают за стабильность, контроль логов, backup/restore, observability.
* **Конечные пользователи** — через домен/ingress получают доступ к сервисам; для них важно, чтобы сервисы были доступны, стабильны, с приемлемой производительностью.

### 2.4 Ограничения

* Система должна работать на on-prem инфраструктуре — ограничения по железу, сети, storage, доступу.
* Использование открытых технологий (GitLab self-managed, Helm, Kubernetes, Prometheus, Ceph/Rook, open-source).
* Без доступа к внешним облакам (cloud), всё на собственных серверах.
* Требования безопасности: ограниченный доступ, ограничения на сторонний софт, контроль образов, IAM, network policies.
* Обратная совместимость: деплой старых версий, rollback, минимизация времени простоя.

### 2.5 Допущения и зависимости

* Предполагается, что железо уже настроено, кластер Kubernetes может быть поднят, существуют базовая сеть и storage.
* Предполагается, что разработчики и DevOps имеют необходимые привилегии доступов.
* Зависимость от стабильной работы GitLab, registry, Ceph/Rook, Kubernetes — отказ любого может повлиять на систему.
* Предполагается, что микросервисы, которые будут деплоиться, сами реализованы согласно контрактам (API), healthcheck, конфигурации.

---

Верно, ты прав — согласно твоей просьбе предыдущие требования стоило писать на русском. Вот исправленная версия важных требований в разделе **3. СПЕЦИФИЧЕСКИЕ ТРЕБОВАНИЯ** из SRS, полностью на русском.

---

## 3. СПЕЦИФИЧЕСКИЕ ТРЕБОВАНИЯ

### 3.1 Функциональные требования

#### 3.1.1 Модуль: Контроль версий & CI/CD

* **FR-VC1**: Система должна автоматически запускать CI/CD-pipeline при пуше кода в репозиторий (при коммите или слиянии ветки).
* **FR-VC2**: Система должна собирать Docker/OCI-образ для соответствующего микросервиса.
* **FR-VC3**: В рамках pipeline должны выполняться автоматические тесты (unit и интеграционные).
* **FR-VC4**: При успешном проходе pipeline система должна публиковать (push) собранный образ в реестр образов.
* **FR-VC5**: Система должна сохранять артефакты сборки (логи, бинарные артефакты, результаты тестов) и предоставлять доступ для просмотра.
* **FR-VC6**: Система должна позволять запуск pipeline вручную (DevOps или разработчиками).
* **FR-VC7**: Система должна хранить метаданные сборки: SHA коммита, ID pipeline, digest образа, время сборки, статус.

#### 3.1.2 Модуль: Деплой и управление релизами

* **FR-DEP1**: Система должна автоматически деплоить образ в dev-окружение после успешного pipeline.
* **FR-DEP2**: Система должна позволять вручную продвигать (promote) билды в production-окружение после одобрения.
* **FR-DEP3**: Развёртывание сервисов должно происходить через Helm-чарты с поддержкой конфигураций (переменные среды, секреты, ingress/домен, маршрутизация).
* **FR-DEP4**: Система должна позволять откат (rollback) к предыдущей стабильной версии, если новый релиз не прошёл проверки здоровья или тесты.
* **FR-DEP5**: Система должна поддерживать несколько окружений (dev, staging, prod) с изолированной конфигурацией.
* **FR-DEP6**: Система должна хранить информацию о каждом релизе: образ, версия чарта, дата, статус, окружение.

#### 3.1.3 Модуль: Управление конфигурацией и секретами

* **FR-CFG1**: Система должна обеспечивать внешнюю конфигурацию для разных окружений (переменные среды, файлы конфигурации).
* **FR-CFG2**: Система должна позволять задавать домены/хосты, TLS-сертификаты, правила ingress/маршрутизации, порты и прочие параметры на уровне чарта.
* **FR-CFG3**: Система должна поддерживать безопасное хранение секретов (учётные данные, ключи API) и их инъекцию при деплое (например, через Kubernetes Secrets или Vault).

#### 3.1.4 Модуль: Мониторинг и логирование

* **FR-MON1**: Система должна собирать метрики на уровне сервисов и кластера (CPU, память, request rate, error rate и т. д.).
* **FR-MON2**: Метрики должны сохраняться в time-series БД (например, Prometheus) и отображаться через dashboard (Grafana).
* **FR-MON3**: Система должна иметь правила alerting: сервис недоступен, высокая ошибка, перегрузка ресурсов и др.
* **FR-MON4**: Система должна собирать логи (stdout/stderr) сервисов, хранить их (например, через Loki / EFK) и предоставлять поиск по сервису, времени, уровню.
* **FR-MON5**: Каждый микросервис должен иметь endpoint для health-check; deployment должен проверять готовность перед пометкой релиза как «активный».

#### 3.1.5 Модуль: Контроль доступа и аудит

* **FR-SEC1**: Система должна обеспечивать ролевую модель доступа: роли Developer, DevOps, Admin с различными правами на deploy, approve, rollback, конфигурацию.
* **FR-SEC2**: Все критичные действия: деплой, promote, rollback, сборка, пуш образа, изменения конфигурации — должны логироваться с метаданными (кто, когда, что).
* **FR-SEC3**: Аудит-логи должны храниться (либо по retention policy) для возможности расследования инцидентов.

### 3.2 Нефункциональные требования

#### 3.2.1 Производительность

* **NFR-PERF1**: Время от запуска сборки до публикации образа (build → push) не должно превышать заданного порога (например, 15 минут) при нормальной нагрузке.
* **NFR-PERF2**: Время отката (rollback) не должно превышать, например, 5 минут.
* **NFR-PERF3**: Система должна выдерживать параллельные pipeline-сборки минимум для 5 микросервисов без значительного ухудшения производительности.

#### 3.2.2 Надёжность / Доступность

* **NFR-REL1**: Сервисы, развернутые в production, должны обеспечивать доступность ≥ 99.9%.
* **NFR-REL2**: Система должна поддерживать откат (rollback) релизов, чтобы обеспечить восстановление после ошибки.
* **NFR-REL3**: Registry и storage должны иметь репликацию/резервирование, чтобы предотвратить потерю данных.

#### 3.2.3 Безопасность

* **NFR-SEC1**: Только аутентифицированные и авторизованные пользователи могут выполнять деплой в prod.
* **NFR-SEC2**: Секреты (пароли, ключи) должны быть зашифрованы при хранении и передаче.
* **NFR-SEC3**: Образы перед деплоем в prod должны проходить сканирование на известные уязвимости.
* **NFR-SEC4**: Kubernetes-RBAC / network policies должны ограничивать межсервисное взаимодействие по принципу минимальных прав.

#### 3.2.4 Удобство использования

* **NFR-US1**: Разработчики должны иметь возможность запускать pipeline через git push / merge request без дополнительных действий.
* **NFR-US2**: Дашборды мониторинга и конфигурации алертов должны быть доступны через веб-интерфейс и визуально понятны.
* **NFR-US3**: История релизов, логов, аудита должна быть доступна через UI/CLI для просмотра и поиска.

#### 3.2.5 Совместимость / Переносимость

* **NFR-COM1**: Система должна работать на Linux-серверах (bare-metal или виртуалки).
* **NFR-COM2**: Docker-образы должны быть OCI-совместимы.
* **NFR-COM3**: Kubernetes-кластеры должны соответствовать версии не ниже заранее указанной (например, ≥ 1.23).

#### 3.2.6 Масштабируемость

* **NFR-SCL1**: Система должна поддерживать рост числа микросервисов (от ~5 до ~100+) без значительных изменений конфигурации.
* **NFR-SCL2**: CI/CD runners, registry и storage должны быть масштабируемы горизонтально при росте нагрузки.

### 3.3 Требования к интерфейсам

#### 3.3.1 Пользовательские интерфейсы

* Веб-интерфейс self-managed GitLab для работы с репозиториями, MR, pipeline, логами, историей.
* Веб-интерфейс мониторинга (Grafana) + доступ к alert-консоли.
* При необходимости — интерфейс управления конфигурациями/секретами (UI или CLI).

#### 3.3.2 Программные интерфейсы

* Docker/OCI Registry API (push/pull).
* Kubernetes API (для deployment, rollback, управление ресурсами).
* Helm API / CLI (развёртывание чарта, обновление, rollback).
* API микросервисов (REST / gRPC) — контракты, healthcheck, взаимодействие между сервисами.
* API мониторинга (Prometheus), alerting (Alertmanager), логирования (Loki / EFK).

#### 3.3.3 Аппаратные интерфейсы

* Серверы / виртуалки / bare-metal(без использования виртуализации), сеть, дисковая подсистема (storage), firewall — должны поддерживать работу Kubernetes, registry, storage.

#### 3.3.4 Коммуникационные интерфейсы

* TLS/HTTPS — для доступа к registry, GitLab, сервисам, ingress.
* Внутренний сетевой слой (CNI/overlay) — для межсервисного взаимодействия.
* Протоколы обмена сообщений (например, AMQP для брокеров сообщений).

---

## 4. Модели системы

### 4.1 Use Case Diagrams

(смотреть ранее предоставленные диаграммы use-case).

### 4.2 Sequence Diagrams

(по основным сценариям: commit → pipeline → build → push → deploy → healthcheck → release; failure → rollback).

### 4.3 Data Model / ER Diagram

(смотреть ER-диаграмму; хранит метаданные: commits, pipelines, images, releases, audit log, metrics, alerts, artifacts и т.д.).

---

## 5. Требования к документации

### 5.1 Пользоватеская документация

* Руководство пользователя / разработчика: как делать коммиты, trigger pipeline, promote, rollback, просматривать логи, использовать мониторинг.
* Руководство DevOps: как настраивать runner, registry, storage, кластеры, backup/restore, секреты.
* FAQ / Troubleshooting — часто возникающие ошибки, recovery сценарии, rollback.

### 5.2 Техническая документация

* Архитектурное описание системы (диаграммы, компоненты, зависимости).
* Описание CI/CD pipeline, step-by-step, переменные, секреты.
* Документация Helm-чартов, конфигураций, environment values.
* Документация по мониторингу, логированию, alert rules.
* Security policy: управление доступом, RBAC, секреты, скан обоев.

### 5.3 База знаний / Системный помощник

* В случае необходимости — встроенная справка (README, Wiki), описание API, контрактов, форматов.

---

## 6. Критерии приёмки

### 6.1 Функциональная приемка

* Все критические функциональные требования (FR-VC1..FR-DEP5, FR-MON1..FR-MON5, FR-SEC1..FR-SEC3) реализованы, протестированы, успешно проходят тест-кейсы;
* Возможность выполнить деплой → rollback;
* Пуш/пул образов работает, артефакты сохраняются, метаданные корректны;
* Мониторинг и alerting функционируют для ключевых сценариев;
* Аудит логов ведётся, доступен интерфейс просмотра/поиска.

### 6.2 Нефункциональная приемка

* Время сборки/push/deploy/rollback в пределах установленных NFR (см. пункты 3.2);
* Доступность — сервисы выдерживают заданный SLA (availability, response time);
* Безопасность — скан образов пройдён, RBAC/секреты настроены, нет критических уязвимостей;
* Масштабируемость — система выдерживает рост нагрузки (число сервисов, число пользователей, параллельные сборки);
* Документация присутствует, инструкции понятны, тесты покрывают основные сценарии.

---

## Пояснение и рекомендации

* Основано на стандартах IEEE 830-1998 (RSP template) и ISO/IEC/IEEE 29148. ([Бухарестский университет][2])
* Требования сформулированы так, чтобы быть **конкретными, проверяемыми, однозначными, полными, трассируемыми**. ([se.inf.ethz.ch][3])

[1]: https://habr.com/ru/articles/328822/ "Стандарты и шаблоны для ТЗ на разработку ПО / Хабр"
[2]: https://bohr.wlu.ca/cp317/notes/IEEE_830.pdf "IEEE Std 830-1998"
[3]: https://se.inf.ethz.ch/courses/2015b_fall/dsl/slides/04-requirements.pdf "Chair of Software Engineering"
